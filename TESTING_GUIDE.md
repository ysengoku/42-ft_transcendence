# ğŸ§ª Guide Complet des Tests - Projet Transcendence

Ce guide explique comment utiliser et comprendre les tests unitaires dans le projet Transcendence, de A Ã  Z, mÃªme si vous n'avez jamais fait de tests auparavant.

## ğŸ“š Table des matiÃ¨res

1. [Qu'est-ce que les tests unitaires ?](#quest-ce-que-les-tests-unitaires-)
2. [DÃ©marrage de l'environnement](#dÃ©marrage-de-lenvironnement)
3. [Structure des tests](#structure-des-tests)
4. [Lancer les tests](#lancer-les-tests)
5. [Comprendre les options](#comprendre-les-options)
6. [Comprendre les assertions](#comprendre-les-assertions)
7. [Cycle de vie d'un test](#cycle-de-vie-dun-test)
8. [InterprÃ©ter les rÃ©sultats](#interprÃ©ter-les-rÃ©sultats)
9. [DÃ©boguer les tests](#dÃ©boguer-les-tests)
10. [Bonnes pratiques](#bonnes-pratiques)

---

## ğŸ¤” Qu'est-ce que les tests unitaires ?

Les **tests unitaires** sont des petits programmes qui vÃ©rifient automatiquement que votre code fonctionne comme prÃ©vu. Imaginez que vous testez une calculatrice :

```python
def test_addition():
    result = calculer(2 + 3)
    assert result == 5  # VÃ©rifie que 2+3 donne bien 5
```

Dans notre projet Transcendence, nous testons les **endpoints API** (les URLs que le frontend appelle) pour vÃ©rifier qu'ils :
- Retournent les bonnes donnÃ©es
- GÃ¨rent correctement les erreurs
- Respectent les permissions
- Fonctionnent dans tous les scÃ©narios

---

## ğŸ³ DÃ©marrage de l'environnement

### 1. DÃ©marrer Docker

Avant de lancer les tests, vous devez dÃ©marrer l'environnement Docker :

```bash
# Aller dans le dossier du projet
cd /chemin/vers/projet

# DÃ©marrer tous les services Docker
make up
```

**Que se passe-t-il ?** Cette commande lance :
- ğŸ—„ï¸ Une base de donnÃ©es PostgreSQL
- ğŸ Le serveur Django (backend)
- ğŸŒ Le serveur frontend (Vite)
- ğŸ”§ Nginx (proxy)
- â° Un service de tÃ¢ches planifiÃ©es

### 2. VÃ©rifier que tout fonctionne

```bash
# VÃ©rifier que les conteneurs sont lancÃ©s
docker ps

# Vous devriez voir 5 conteneurs en cours d'exÃ©cution
```

### 3. Lancer les tests avec statistiques (RecommandÃ©)

```bash
# Script avec statistiques dÃ©taillÃ©es (nouveau !)
./test_with_stats.sh

# Pour un module spÃ©cifique
./test_with_stats.sh users
./test_with_stats.sh chat
./test_with_stats.sh pong
./test_with_stats.sh tournaments
```

### 4. MÃ©thode alternative : Entrer dans le conteneur

```bash
# MÃ©thode 1 : Avec Make (recommandÃ©)
make bash-backend

# MÃ©thode 2 : Directement avec Docker
docker exec -it server bash
```

**Vous Ãªtes maintenant dans le conteneur Django** oÃ¹ vous pouvez lancer les tests !

---

## ğŸ“ Structure des tests

### Organisation des fichiers

```
server/
â”œâ”€â”€ users/tests/
â”‚   â”œâ”€â”€ test_auth_endpoints.py      # Tests d'authentification
â”‚   â”œâ”€â”€ test_mfa_endpoints.py       # Tests MFA (2FA)
â”‚   â”œâ”€â”€ test_oauth2_endpoints.py    # Tests OAuth (GitHub, 42)
â”‚   â””â”€â”€ test_users_endpoints.py     # Tests gestion utilisateurs
â”œâ”€â”€ chat/tests/
â”‚   â”œâ”€â”€ test_chat_endpoints.py      # Tests chat et messages
â”‚   â””â”€â”€ test_notifications_endpoints.py # Tests notifications
â”œâ”€â”€ pong/tests/
â”‚   â””â”€â”€ test_game_stats_endpoints.py # Tests statistiques de jeu
â””â”€â”€ tournaments/tests/
    â””â”€â”€ test_tournaments_endpoints.py # Tests tournois
```

### Anatomie d'un fichier de test

```python
import logging
from django.test import TestCase
from users.models import User

class AuthEndpointsTests(TestCase):  # Classe de tests
    
    def setUp(self):  # PrÃ©paration avant chaque test
        """ExÃ©cutÃ© AVANT chaque test individuel"""
        logging.disable(logging.CRITICAL)  # DÃ©sactive les logs
        # CrÃ©er des donnÃ©es de test
        self.user = User.objects.create_user(
            "TestUser", 
            email="test@example.com", 
            password="TestPassword123"
        )
    
    def tearDown(self):  # Nettoyage aprÃ¨s chaque test
        """ExÃ©cutÃ© APRÃˆS chaque test individuel"""
        logging.disable(logging.NOTSET)  # RÃ©active les logs
        # Django supprime automatiquement les donnÃ©es de test
    
    def test_login_with_correct_credentials(self):  # Un test
        """Test que la connexion fonctionne avec de bons identifiants"""
        # Arrange : PrÃ©parer les donnÃ©es
        data = {"username": "TestUser", "password": "TestPassword123"}
        
        # Act : ExÃ©cuter l'action Ã  tester
        response = self.client.post("/api/login", 
                                  content_type="application/json", 
                                  data=data)
        
        # Assert : VÃ©rifier le rÃ©sultat
        self.assertEqual(response.status_code, 200)
        self.assertEqual(response.json()["username"], "TestUser")
```

---

## ğŸš€ Lancer les tests

### ğŸ¯ MÃ©thode recommandÃ©e : Avec statistiques

```bash
# Depuis la racine du projet (plus simple et avec stats !)
# IMPORTANT : Docker doit Ãªtre lancÃ© avec 'make up' d'abord

# 1. Lancer TOUS les tests avec statistiques
make tests
# ou
./test_with_stats.sh

# 2. Lancer tests par module avec statistiques  
make tests-users      # Tests utilisateurs & auth
make tests-chat       # Tests chat & notifications
make tests-pong       # Tests jeu & statistiques
make tests-tournaments # Tests tournois

# Ou directement avec le script :
./test_with_stats.sh users
./test_with_stats.sh chat
./test_with_stats.sh pong
./test_with_stats.sh tournaments
```

**Exemple de sortie :**
```
ğŸ§ª Running Django Tests with Statistics
========================================
ğŸ¯ Running tests for: users
[sortie normale des tests...]

ğŸ“Š SUMMARY
==========
Total tests: 70
âœ… Passed: 49 (70%)
âŒ Failed: 14 (20%) 
ğŸ’¥ Errors: 7 (10%)
ğŸ¯ Success rate: 70%
ğŸŸ¡ Status: GOOD
```

### ğŸ”§ MÃ©thode alternative : Commandes manuelles

```bash
# IMPORTANT : Vous devez Ãªtre dans le conteneur backend
# (utilisez `make bash-backend` depuis la racine du projet)

# 1. Lancer TOUS les tests du projet
python manage.py test

# 2. Lancer tous les tests d'une app
python manage.py test users
python manage.py test chat
python manage.py test pong
python manage.py test tournaments

# 3. Lancer un fichier de test spÃ©cifique
python manage.py test users.tests.test_auth_endpoints

# 4. Lancer une classe de tests spÃ©cifique
python manage.py test users.tests.test_auth_endpoints.AuthEndpointsTests

# 5. Lancer un test individuel
python manage.py test users.tests.test_auth_endpoints.AuthEndpointsTests.test_login_with_correct_credentials
```

### Lancer uniquement les nouveaux tests crÃ©Ã©s

```bash
# Tous les nouveaux tests endpoints en une commande
python manage.py test \
  users.tests.test_auth_endpoints \
  users.tests.test_mfa_endpoints \
  users.tests.test_oauth2_endpoints \
  chat.tests.test_chat_endpoints \
  chat.tests.test_notifications_endpoints \
  pong.tests.test_game_stats_endpoints \
  tournaments.tests.test_tournaments_endpoints
```

### Tests par thÃ©matique

```bash
# Tests d'authentification uniquement
python manage.py test \
  users.tests.test_auth_endpoints \
  users.tests.test_mfa_endpoints \
  users.tests.test_oauth2_endpoints

# Tests de communication (chat + notifications)
python manage.py test \
  chat.tests.test_chat_endpoints \
  chat.tests.test_notifications_endpoints

# Tests de jeu
python manage.py test \
  pong.tests.test_game_stats_endpoints \
  tournaments.tests.test_tournaments_endpoints
```

---

## âš™ï¸ Comprendre les options

### L'option `--verbosity` (niveau de dÃ©tail)

```bash
# --verbosity=0 : Silencieux (seulement les erreurs)
python manage.py test users.tests.test_auth_endpoints --verbosity=0

# --verbosity=1 : Basique (par dÃ©faut)
python manage.py test users.tests.test_auth_endpoints --verbosity=1

# --verbosity=2 : DÃ©taillÃ© (recommandÃ© pour dÃ©boguer)
python manage.py test users.tests.test_auth_endpoints --verbosity=2

# --verbosity=3 : TrÃ¨s dÃ©taillÃ© (toutes les informations)
python manage.py test users.tests.test_auth_endpoints --verbosity=3
```

**Exemple de sortie avec verbosity=2 :**
```
Creating test database for alias 'default' ('test_your_database_name')...
Operations to perform:
  Synchronize unmigrated apps: channels, daphne, messages, staticfiles
  Apply all migrations: admin, auth, chat, contenttypes, pong, sessions, silk, sites, tournaments, users
System check identified no issues (0 silenced).
test_login_with_bad_data (users.tests.test_auth_endpoints.AuthEndpointsTests) ... ok
test_login_with_correct_credentials (users.tests.test_auth_endpoints.AuthEndpointsTests) ... ok
test_login_with_empty_data (users.tests.test_auth_endpoints.AuthEndpointsTests) ... ok

----------------------------------------------------------------------
Ran 3 tests in 2.451s

OK
Destroying test database for alias 'default' ('test_your_database_name')...
```

### Autres options utiles

```bash
# --keepdb : Garde la base de test (plus rapide pour les tests rÃ©pÃ©tÃ©s)
python manage.py test users.tests.test_auth_endpoints --keepdb

# --reverse : Lance les tests dans l'ordre inverse
python manage.py test users.tests.test_auth_endpoints --reverse

# --debug-mode : Mode debug (affiche plus d'infos en cas d'erreur)
python manage.py test users.tests.test_auth_endpoints --debug-mode

# --failfast : ArrÃªte au premier test qui Ã©choue
python manage.py test users.tests.test_auth_endpoints --failfast

# --dry-run : Montre quels tests seraient lancÃ©s sans les exÃ©cuter
python manage.py test users.tests.test_auth_endpoints --dry-run
```

---

## ğŸ” Comprendre les assertions

Les **assertions** sont des vÃ©rifications que nous faisons dans les tests. Si une assertion Ã©choue, le test Ã©choue.

### Assertions de base

```python
# 1. Ã‰galitÃ©
self.assertEqual(a, b)          # VÃ©rifie que a == b
self.assertNotEqual(a, b)       # VÃ©rifie que a != b

# Exemples concrets
self.assertEqual(response.status_code, 200)  # Le serveur a rÃ©pondu avec succÃ¨s
self.assertEqual(user.username, "TestUser")  # Le nom d'utilisateur est correct

# 2. VÃ©ritÃ©/FaussetÃ©
self.assertTrue(condition)      # VÃ©rifie que condition est True
self.assertFalse(condition)     # VÃ©rifie que condition est False

# Exemples
self.assertTrue(user.is_active)     # L'utilisateur est actif
self.assertFalse(user.is_staff)     # L'utilisateur n'est pas admin

# 3. PrÃ©sence/Absence
self.assertIsNone(value)        # VÃ©rifie que value est None
self.assertIsNotNone(value)     # VÃ©rifie que value n'est pas None

# Exemples
self.assertIsNone(user.last_login)       # PremiÃ¨re connexion
self.assertIsNotNone(response.json())    # La rÃ©ponse contient du JSON

# 4. Collections
self.assertIn(item, collection)     # VÃ©rifie que item est dans collection
self.assertNotIn(item, collection)  # VÃ©rifie que item n'est pas dans collection

# Exemples
self.assertIn("username", response.json())           # Le JSON contient "username"
self.assertIn("access_token", response.cookies)      # Les cookies contiennent le token
```

### Assertions spÃ©cifiques au web

```python
# 1. Code de statut HTTP
self.assertEqual(response.status_code, 200)  # SuccÃ¨s
self.assertEqual(response.status_code, 401)  # Non autorisÃ©
self.assertEqual(response.status_code, 404)  # Non trouvÃ©
self.assertEqual(response.status_code, 422)  # DonnÃ©es invalides

# 2. Contenu de la rÃ©ponse
self.assertContains(response, "text", status_code=200)
# VÃ©rifie que la rÃ©ponse contient "text" ET que le code est 200

# Exemples
self.assertContains(response, "Username or password are not correct", status_code=401)
self.assertContains(response, "Account successfully deleted", status_code=200)

# 3. JSON
response_data = response.json()
self.assertEqual(response_data["username"], "TestUser")
self.assertIn("access_token", response.cookies)
```

### Comparaisons avec messages personnalisÃ©s

```python
# Ajouter un message explicatif si l'assertion Ã©choue
self.assertEqual(
    response.status_code, 
    200, 
    "La connexion devrait rÃ©ussir avec de bons identifiants"
)

self.assertEqual(
    response.json()["username"], 
    "TestUser", 
    "Le nom d'utilisateur dans la rÃ©ponse devrait Ãªtre 'TestUser'"
)
```

---

## ğŸ”„ Cycle de vie d'un test

### Ordre d'exÃ©cution

```python
class MonTestCase(TestCase):
    
    @classmethod
    def setUpClass(cls):
        """1. ExÃ©cutÃ© UNE FOIS au dÃ©but de la classe"""
        super().setUpClass()
        # Configuration globale pour tous les tests
        print("ğŸ—ï¸  Configuration de la classe")
    
    def setUp(self):
        """2. ExÃ©cutÃ© AVANT CHAQUE test individuel"""
        print("ğŸ”§ PrÃ©paration du test")
        # CrÃ©er des donnÃ©es de test
        self.user = User.objects.create_user("test", "test@test.com", "pass123")
    
    def test_quelque_chose(self):
        """3. Le test lui-mÃªme"""
        print("ğŸ§ª ExÃ©cution du test")
        # Votre test ici
        response = self.client.post("/api/login", data={...})
        self.assertEqual(response.status_code, 200)
    
    def tearDown(self):
        """4. ExÃ©cutÃ© APRÃˆS CHAQUE test individuel"""
        print("ğŸ§¹ Nettoyage du test")
        # Django nettoie automatiquement la base de donnÃ©es
        # Vous pouvez ajouter du nettoyage personnalisÃ© ici
    
    @classmethod
    def tearDownClass(cls):
        """5. ExÃ©cutÃ© UNE FOIS Ã  la fin de la classe"""
        super().tearDownClass()
        print("ğŸ Nettoyage de la classe")
```

### Exemple avec plusieurs tests

```python
class AuthTests(TestCase):
    
    def setUp(self):
        print("ğŸ”§ CrÃ©ation de l'utilisateur de test")
        self.user = User.objects.create_user("test", "test@test.com", "pass123")
    
    def test_login_success(self):
        print("ğŸ§ª Test de connexion rÃ©ussie")
        # Ce test utilise self.user crÃ©Ã© dans setUp()
        
    def test_login_failure(self):
        print("ğŸ§ª Test de connexion Ã©chouÃ©e") 
        # Ce test utilise AUSSI self.user (nouveau setUp() appelÃ©)
    
    def tearDown(self):
        print("ğŸ§¹ Nettoyage aprÃ¨s le test")
        # self.user est automatiquement supprimÃ© par Django
```

**Ordre d'exÃ©cution :**
```
ğŸ—ï¸  Configuration de la classe
ğŸ”§ PrÃ©paration du test
ğŸ§ª Test de connexion rÃ©ussie
ğŸ§¹ Nettoyage aprÃ¨s le test
ğŸ”§ PrÃ©paration du test  (nouveau setUp pour le 2e test)
ğŸ§ª Test de connexion Ã©chouÃ©e
ğŸ§¹ Nettoyage aprÃ¨s le test
ğŸ Nettoyage de la classe
```

### Pourquoi setUp/tearDown ?

```python
# âŒ MAUVAIS : Tests dÃ©pendants les uns des autres
class MauvaisTests(TestCase):
    def test_create_user(self):
        user = User.objects.create_user("test", "test@test.com", "pass123")
        # Le user reste en base
    
    def test_login_user(self):
        # Ce test DÃ‰PEND du test prÃ©cÃ©dent !
        # Si test_create_user Ã©choue, celui-ci Ã©choue aussi
        response = self.client.post("/api/login", ...)

# âœ… BON : Tests indÃ©pendants
class BonsTests(TestCase):
    def setUp(self):
        # Chaque test a ses propres donnÃ©es fraÃ®ches
        self.user = User.objects.create_user("test", "test@test.com", "pass123")
    
    def test_create_user(self):
        # Test indÃ©pendant avec self.user
        
    def test_login_user(self):
        # Test indÃ©pendant avec self.user (diffÃ©rent du test prÃ©cÃ©dent)
```

---

## ğŸ“Š InterprÃ©ter les rÃ©sultats

### Test qui rÃ©ussit

```bash
test_login_with_correct_credentials (users.tests.test_auth_endpoints.AuthEndpointsTests) ... ok

----------------------------------------------------------------------
Ran 1 test in 0.834s

OK
```

**Signification :**
- âœ… `ok` : Le test a rÃ©ussi
- â±ï¸ `0.834s` : Le test a pris 0.834 secondes
- ğŸ‰ `OK` : Tous les tests ont rÃ©ussi

### Test qui Ã©choue

```bash
test_verify_mfa_with_invalid_user (users.tests.test_mfa_endpoints.MfaEndpointsTests) ... FAIL

======================================================================
FAIL: test_verify_mfa_with_invalid_user (users.tests.test_mfa_endpoints.MfaEndpointsTests)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/app/users/tests/test_mfa_endpoints.py", line 58, in test_verify_mfa_with_invalid_user
    self.assertEqual(response.status_code, 404)
AssertionError: 422 != 404

----------------------------------------------------------------------
Ran 1 test in 0.414s

FAILED (failures=1)
```

**Signification :**
- âŒ `FAIL` : Le test a Ã©chouÃ©
- ğŸ“ `line 58` : L'erreur est Ã  la ligne 58
- ğŸ” `AssertionError: 422 != 404` : On attendait 404, on a reÃ§u 422
- ğŸ“ˆ `failures=1` : 1 test a Ã©chouÃ©

### Test avec erreur

```bash
test_something (app.tests.TestCase) ... ERROR

======================================================================
ERROR: test_something (app.tests.TestCase)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/app/app/tests.py", line 10, in test_something
    result = undefined_function()
NameError: name 'undefined_function' is not defined
```

**DiffÃ©rence entre FAIL et ERROR :**
- ğŸ”´ **FAIL** : Une assertion a Ã©chouÃ© (comportement inattendu)
- ğŸ’¥ **ERROR** : Le code a plantÃ© (bug dans le test)

### Tests ignorÃ©s

```bash
test_something (app.tests.TestCase) ... skipped 'Reason for skipping'
```

**UtilisÃ© avec :**
```python
from unittest import skip

@skip("Cette fonctionnalitÃ© n'est pas encore implÃ©mentÃ©e")
def test_future_feature(self):
    pass
```

---

## ğŸ› DÃ©boguer les tests

### 1. Lancer un seul test pour isoler le problÃ¨me

```bash
# Au lieu de lancer tous les tests
python manage.py test users.tests.test_auth_endpoints

# Lancer juste le test qui pose problÃ¨me
python manage.py test users.tests.test_auth_endpoints.AuthEndpointsTests.test_login_with_correct_credentials --verbosity=2
```

### 2. Ajouter des prints de debug

```python
def test_login_with_correct_credentials(self):
    data = {"username": "TestUser", "password": "TestPassword123"}
    
    print(f"ğŸ” DonnÃ©es envoyÃ©es : {data}")  # Debug
    
    response = self.client.post("/api/login", 
                              content_type="application/json", 
                              data=data)
    
    print(f"ğŸ” Code de rÃ©ponse : {response.status_code}")  # Debug
    print(f"ğŸ” Contenu de la rÃ©ponse : {response.content}")  # Debug
    
    self.assertEqual(response.status_code, 200)
```

### 3. Utiliser le debugger Python

```python
def test_login_with_correct_credentials(self):
    data = {"username": "TestUser", "password": "TestPassword123"}
    
    import pdb; pdb.set_trace()  # Point d'arrÃªt
    
    response = self.client.post("/api/login", 
                              content_type="application/json", 
                              data=data)
    
    self.assertEqual(response.status_code, 200)
```

### 4. Examiner la base de donnÃ©es de test

```python
def test_something(self):
    # Voir tous les utilisateurs crÃ©Ã©s
    users = User.objects.all()
    print(f"ğŸ” Utilisateurs en base : {[u.username for u in users]}")
    
    # VÃ©rifier qu'un utilisateur existe
    user_exists = User.objects.filter(username="TestUser").exists()
    print(f"ğŸ” TestUser existe : {user_exists}")
```

### 5. ProblÃ¨mes courants et solutions

#### ProblÃ¨me : "AssertionError: 422 != 404"

```python
# Le code attend une erreur 404 mais reÃ§oit 422
self.assertEqual(response.status_code, 404)  # âŒ Attendu
# Mais le serveur renvoie 422 (donnÃ©es invalides)

# Solution : VÃ©rifier ce que renvoie vraiment l'endpoint
print(f"Code reÃ§u : {response.status_code}")
print(f"Message : {response.content}")
# Puis ajuster le test
self.assertEqual(response.status_code, 422)  # âœ… CorrigÃ©
```

#### ProblÃ¨me : "KeyError: 'username'"

```python
# Le test essaie d'accÃ©der Ã  une clÃ© qui n'existe pas
response_data = response.json()
username = response_data["username"]  # âŒ ClÃ© inexistante

# Solution : VÃ©rifier le contenu du JSON
print(f"JSON reÃ§u : {response.json()}")
# Puis utiliser la bonne clÃ© ou vÃ©rifier qu'elle existe
self.assertIn("username", response_data)
username = response_data["username"]
```

#### ProblÃ¨me : "DoesNotExist: User matching query does not exist"

```python
# Le test essaie d'utiliser un utilisateur qui n'existe pas
user = User.objects.get(username="NonExistentUser")  # âŒ

# Solution : VÃ©rifier que l'utilisateur est crÃ©Ã© dans setUp()
def setUp(self):
    self.user = User.objects.create_user(
        "TestUser",  # âœ… Bien s'assurer du nom
        email="test@example.com",
        password="TestPassword123"
    )
```

---

## ğŸ“‹ Bonnes pratiques

### 1. Nommage des tests

```python
# âœ… BON : Nom explicite
def test_login_with_correct_credentials_returns_user_data(self):
    pass

def test_login_with_invalid_password_returns_401_error(self):
    pass

def test_get_user_profile_while_logged_out_returns_401(self):
    pass

# âŒ MAUVAIS : Nom vague
def test_login(self):
    pass

def test_user_stuff(self):
    pass
```

### 2. Structure AAA (Arrange, Act, Assert)

```python
def test_login_with_correct_credentials(self):
    # ARRANGE : PrÃ©parer les donnÃ©es
    username = "TestUser"
    password = "TestPassword123"
    login_data = {"username": username, "password": password}
    
    # ACT : ExÃ©cuter l'action
    response = self.client.post("/api/login", 
                              content_type="application/json", 
                              data=login_data)
    
    # ASSERT : VÃ©rifier les rÃ©sultats
    self.assertEqual(response.status_code, 200)
    response_data = response.json()
    self.assertEqual(response_data["username"], username)
    self.assertIn("access_token", response.cookies)
```

### 3. Un test = une fonctionnalitÃ©

```python
# âœ… BON : Un test teste une chose
def test_login_with_correct_credentials_succeeds(self):
    # Teste seulement la connexion rÃ©ussie
    pass

def test_login_sets_access_token_cookie(self):
    # Teste seulement que le cookie est dÃ©fini
    pass

def test_login_returns_user_profile_data(self):
    # Teste seulement que les donnÃ©es utilisateur sont renvoyÃ©es
    pass

# âŒ MAUVAIS : Un test teste plusieurs choses
def test_login_does_everything(self):
    # Teste la connexion ET les cookies ET les donnÃ©es ET les permissions...
    pass
```

### 4. Isolation des tests

```python
# âœ… BON : Chaque test est indÃ©pendant
class AuthTests(TestCase):
    def setUp(self):
        # DonnÃ©es fraÃ®ches pour chaque test
        self.user = User.objects.create_user("test", "test@test.com", "pass123")
    
    def test_login_success(self):
        # Utilise self.user
        pass
    
    def test_login_failure(self):
        # Utilise self.user (diffÃ©rent du test prÃ©cÃ©dent)
        pass

# âŒ MAUVAIS : Tests dÃ©pendants
class AuthTests(TestCase):
    def test_create_user(self):
        User.objects.create_user("test", "test@test.com", "pass123")
    
    def test_login_user(self):
        # DÃ‰PEND du test prÃ©cÃ©dent !
        pass
```

### 5. Messages d'assertion clairs

```python
# âœ… BON : Message explicite
self.assertEqual(
    response.status_code, 
    200, 
    "La connexion avec des identifiants corrects devrait rÃ©ussir"
)

self.assertIn(
    "access_token", 
    response.cookies,
    "Un token d'accÃ¨s devrait Ãªtre dÃ©fini dans les cookies aprÃ¨s connexion"
)

# âŒ MAUVAIS : Pas de message
self.assertEqual(response.status_code, 200)
self.assertIn("access_token", response.cookies)
```

### 6. Tests de cas limites

```python
# Tester les cas normaux
def test_login_with_correct_credentials(self):
    pass

# Mais aussi les cas d'erreur
def test_login_with_empty_username(self):
    pass

def test_login_with_empty_password(self):
    pass

def test_login_with_nonexistent_user(self):
    pass

def test_login_with_incorrect_password(self):
    pass

def test_login_with_too_long_username(self):
    pass

# Et les cas extrÃªmes
def test_login_with_sql_injection_attempt(self):
    pass

def test_login_with_unicode_characters(self):
    pass
```

---

## ğŸ¯ Commandes de test par niveau

### DÃ©butant

```bash
# Lancer tous les tests d'une app
python manage.py test users --verbosity=2

# Lancer un fichier de test
python manage.py test users.tests.test_auth_endpoints --verbosity=2

# Lancer un test spÃ©cifique
python manage.py test users.tests.test_auth_endpoints.AuthEndpointsTests.test_login_with_correct_credentials --verbosity=2
```

### IntermÃ©diaire

```bash
# Tests multiples avec conservation de la DB
python manage.py test users.tests.test_auth_endpoints users.tests.test_mfa_endpoints --keepdb --verbosity=2

# ArrÃªter au premier Ã©chec
python manage.py test users --failfast --verbosity=2

# Mode debug pour plus d'infos
python manage.py test users.tests.test_auth_endpoints --debug-mode --verbosity=2
```

### AvancÃ©

```bash
# Pattern pour tests spÃ©cifiques
python manage.py test --pattern="*auth*" --verbosity=2

# Tests en parallÃ¨le (plus rapide)
python manage.py test --parallel --verbosity=2

# Tests avec coverage (nÃ©cessite pip install coverage)
coverage run --source='.' manage.py test
coverage report
coverage html  # GÃ©nÃ¨re un rapport HTML
```

---

## ğŸ†˜ Que faire en cas de problÃ¨me ?

### 1. Le conteneur Docker ne dÃ©marre pas
```bash
# VÃ©rifier les logs
make logs

# RedÃ©marrer proprement
make down
make up
```

### 2. Les migrations ne passent pas
```bash
# Dans le conteneur
python manage.py makemigrations
python manage.py migrate
```

### 3. Les tests Ã©chouent tous
```bash
# VÃ©rifier que la base de test se crÃ©e bien
python manage.py test --dry-run --verbosity=3

# Tester un test simple d'abord
python manage.py test users.tests.test_users_endpoints.UsersEndpointsTests.test_get_users_while_logged_out --verbosity=2
```

### 4. Import errors
```bash
# VÃ©rifier la structure Python
python -c "import users.tests.test_auth_endpoints; print('OK')"
```

### 5. Permission denied
```bash
# VÃ©rifier les permissions
ls -la users/tests/
chmod +r users/tests/test_*.py
```

---

## ğŸ“ˆ MÃ©triques de tests

### Compter les tests
```bash
# Voir tous les tests qui seraient exÃ©cutÃ©s
python manage.py test --dry-run

# Compter les tests par app
python manage.py test users --dry-run | grep -c "test_"
python manage.py test chat --dry-run | grep -c "test_"
```

### Temps d'exÃ©cution
```bash
# ChronomÃ©trer les tests
time python manage.py test users.tests.test_auth_endpoints

# Tests avec timing dÃ©taillÃ©
python manage.py test users.tests.test_auth_endpoints --verbosity=2 --timing
```

---

ğŸ‰ **FÃ©licitations !** Vous savez maintenant tout ce qu'il faut pour lancer, comprendre et dÃ©boguer les tests de Transcendence !

*N'hÃ©sitez pas Ã  expÃ©rimenter avec des petits changements dans les tests pour voir comment ils rÃ©agissent. C'est en pratiquant qu'on apprend !*